{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Tuple, Dict, Iterator\n",
    "import torch\n",
    "from dpr.options import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "if (logger.hasHandlers()):\n",
    "    logger.handlers.clear()\n",
    "console = logging.StreamHandler()\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "from dpr.options import init_base_args\n",
    "args = init_base_args(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from dpr.utils.model_utils import load_states_from_checkpoint, setup_for_distributed_mode, get_model_obj\n",
    "from dpr.models import init_biencoder_components\n",
    "#Intermediate dump of a models internal state\n",
    "CheckpointState = collections.namedtuple(\"CheckpointState\",['model_dict', 'optimizer_dict', 'scheduler_dict', 'offset', 'epoch','encoder_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state = load_states_from_checkpoint(args.model_file)\n",
    "set_encoder_params_from_state(saved_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorizer, encoder, _ = init_biencoder_components(args.encoder_model_type, args, inference_only=True)\n",
    "encoder = encoder.question_model\n",
    "\n",
    "#                                       Model, Optimiser, Device,   GPU count,  Rank,            Half-precision fp\n",
    "encoder, _ = setup_for_distributed_mode(encoder, None, args.device, args.n_gpu, args.local_rank, args.fp16)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpr.indexer.faiss_indexers import DenseHNSWFlatIndexer, DenseFlatIndexer\n",
    "from dense_retriever import DenseRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from model file\n",
    "model_to_load = get_model_obj(encoder)\n",
    "logger.info('Reading saved model from %s', args.model_file)\n",
    "\n",
    "prefix_len = len('question_model.')\n",
    "question_encoder_state = {key[prefix_len:]: value for (key, value) in saved_state.model_dict.items() if\n",
    "                            key.startswith('question_model.')}\n",
    "model_to_load.load_state_dict(question_encoder_state, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = model_to_load.get_out_size()\n",
    "logger.info('Encoder vector_size=%d', vector_size)\n",
    "ndex_buffer_sz = args.index_buffer\n",
    "if args.hnsw_index:\n",
    "    index = DenseHNSWFlatIndexer(vector_size)\n",
    "    index_buffer_sz = -1  # encode all at once\n",
    "else:\n",
    "    index = DenseFlatIndexer(vector_size)\n",
    "\n",
    "retriever = DenseRetriever(encoder, args.batch_size, tensorizer, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_files_pattern = args.encoded_ctx_file\n",
    "input_paths = glob.glob(ctx_files_pattern)\n",
    "\n",
    "if args.remove_lang is not None:\n",
    "    final_fps = []\n",
    "\n",
    "    for path in input_paths:\n",
    "        basename = os.path.basename(path)\n",
    "        to_be_removed = False\n",
    "        for lang in args.remove_lang:\n",
    "            if lang in basename:\n",
    "                to_be_removed = True\n",
    "        if to_be_removed is False:\n",
    "            final_fps.append(path)\n",
    "    input_paths = final_fps\n",
    "    print(\"lang {} are removed from retrieval target\".format(input_paths))\n",
    "    index_path = \"_\".join(input_paths[0].split(\"_\")[:-1])\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e23d9eaaa75d3010d1b945c9e961f9d6255048c4f64b314449ab9c4e77b7c83"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
